{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39892161-f8a6-4abc-8926-ff8c36755ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('../')\n",
    "os.system('rm -f ./clades/*')\n",
    "os.system('rm -f ./dumps/*')\n",
    "os.system('rm -f ./real_dumps/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5cb529-49ed-430a-a43d-e6d930c00173",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = Seq('ATGAGAGACA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311457f-c8b4-471c-8b1c-4c9847a5a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict as dd\n",
    "import os\n",
    "import gen_dumps as gd\n",
    "from dumps_to_csv import dtcsv\n",
    "import sys\n",
    "# from kmer_uniq_counts import kmer_uniq\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b6951-e971-4199-84eb-8c81bec1a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Copia_clades.txt', sep = '\\t', names = [i for i in range(1,10)])\n",
    "df = df.fillna(0)\n",
    "minimal_max = 0\n",
    "maximums = []\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c51b64-c2cb-48ed-b381-b8c7aecdd9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_groups(df, column):\n",
    "    grps = {}\n",
    "    for i, row in df.iterrows():\n",
    "        if row[column] not in grps:\n",
    "            grps[row[column]] = []\n",
    "        grps[row[column]].append(i)\n",
    "    return(grps)\n",
    "\n",
    "def make_tree(df,groups, column, last_column = 9):\n",
    "    node = {}\n",
    "    for k, v in groups.items():\n",
    "        # print(f'group {k} passed, column {column-1}')\n",
    "        subgroups = make_groups(df.iloc[v], column) \n",
    "            \n",
    "        if len(subgroups) == 1 or int(column) == last_column:\n",
    "            # print('LAST')\n",
    "            for key, v in subgroups.items(): #k is taken from previous group index\n",
    "                node[k] = v\n",
    "        else:\n",
    "            add_node = make_tree(df, subgroups, column + 1)\n",
    "            node[k] = add_node\n",
    "            \n",
    "    return(node)\n",
    "\n",
    "def kmer_uniq(path, k):\n",
    "    global maximums\n",
    "    f = open(f'{path}')\n",
    "    filtered_kmers = open(f'./{path[:-3]}_filtered.fas', 'w')\n",
    "    filtered_list = []\n",
    "    k_list = []\n",
    "    kmer_names = []\n",
    "    lines = f.readlines()\n",
    "    n = 0\n",
    "    \n",
    "    max = 0\n",
    "    for line in lines:\n",
    "        if '>' in line:\n",
    "            if int(line.strip()[1:]) > max:\n",
    "                max = int(line.strip()[1:])\n",
    "    print(path)\n",
    "    print('max', max)\n",
    "    maximums.append(max)\n",
    "    f.seek(0)\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if '>' in line:\n",
    "            if int(line.strip()[1:]) > max//2:\n",
    "                filtered_list.append(line.strip())\n",
    "                switch = True\n",
    "            else:\n",
    "                switch = False\n",
    "        else:\n",
    "            if switch:\n",
    "                filtered_list.append(line.strip())\n",
    "    filtered_kmers.write('\\n'.join(filtered_list))\n",
    "    filtered_kmers.close()\n",
    "    f.close()\n",
    "\n",
    "    filtered_kmers = open(f'./{path[:-3]}_filtered.fas')\n",
    "    cluster = open(f'../clades/{path}sta')\n",
    "    lines = filtered_kmers.readlines()\n",
    "    # clines = cluster.readlines()\n",
    "    m = 0\n",
    "    for line in lines:\n",
    "        n=0\n",
    "        m+=1\n",
    "        # if m%5000 == 0:\n",
    "        #     print(m)\n",
    "        if '>' not in line:\n",
    "            kmer = line.strip()\n",
    "            kmer_names.append(line.strip())\n",
    "            rev_kmer = Seq(kmer)\n",
    "            rev_kmer = rev_kmer.reverse_complement()\n",
    "            # print(os.getcwd())\n",
    "            # print(f\"grep -e '{kmer}' -e '{rev_kmer}' ../clades/{path}sta | wc -l\")\n",
    "            n = os.system(f\"grep -e '{kmer}' -e '{rev_kmer}' ../clades/{path}sta | wc -l >> n.temp\")\n",
    "            # jojo = input()\n",
    "            # clines = cluster.readlines()\n",
    "            # for cline in clines:\n",
    "            #     rev_seq = Seq(cline.strip())\n",
    "            #     rev_seq = rev_seq.reverse_complement()\n",
    "            #     # if '>' not in cline:\n",
    "            #     if kmer in cline or kmer in rev_seq:\n",
    "            #         n+=1\n",
    "            if m%5000 == 0:\n",
    "                print(kmer, n)\n",
    "            # cluster.seek(0)\n",
    "    k_list = [int(i.strip()) for i in open('n.temp').readlines()]\n",
    "    n = os.system('rm n.temp')\n",
    "    data = {'kmer':kmer_names, 'count':k_list}\n",
    "    uniq_doc_list = []\n",
    "    for c, v in enumerate(kmer_names):\n",
    "        count_value = f'>{k_list[c]}'\n",
    "        uniq_doc_list.append(count_value)\n",
    "        uniq_doc_list.append(v)\n",
    "    path_uniq = open(f'{path[:-3]}_uniq.fasta', 'w')\n",
    "    path_uniq.write('\\n'.join(uniq_doc_list))\n",
    "    path_uniq.close()\n",
    "    os.system(f'rm {path}')\n",
    "    os.system(f'rm ./{path[:-3]}_filtered.fas')\n",
    "    # df = pd.DataFrame.from_dict(data)\n",
    "    filtered_kmers.close()\n",
    "    cluster.close()\n",
    "\n",
    "    print('end')\n",
    "\n",
    "def listdir_nohidden(path='.'):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719ea15-a196-4d00-a167-1b0c029ca4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = make_groups(df, 4)\n",
    "# print(grp)\n",
    "tree = make_tree(df, grp, column = 5, last_column = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5c871-47ff-4c4c-a8a7-805a27594fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ea3d7-36c2-496b-9c96-29a65421e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = pd.read_csv('mmseqs_REPEAT_REGIONS_1_cluster.tsv', sep = '\\t', names = [0,1])\n",
    "seqs_in_clusters = dd(list)\n",
    "for i in df_clusters.iterrows():\n",
    "    seqs_in_clusters[i[1][0].split(':')[1]].append(i[1][1].split(':')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b212b6-9906-49eb-ae42-63a52c1dc16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaves(branch):\n",
    "    global leaves\n",
    "    if type(branch) is list:\n",
    "        leaves.extend(branch)\n",
    "    else:\n",
    "        for k, v in branch.items():\n",
    "            get_leaves(v)\n",
    "            \n",
    "\n",
    "def find_unique(leaf_list):\n",
    "    global maximums\n",
    "    global seqs_in_clusters\n",
    "    global seqs_dict\n",
    "    global kmer_size\n",
    "    all_clades = open('./all_clades.fasta','w') # нужен для подсчета кмеров во всех сравниваемых кладах \n",
    "    for k, v in leaf_list.items():\n",
    "        df_temp = df.iloc[v]\n",
    "        df_temp = df_temp.reset_index(drop=True)\n",
    "        \n",
    "        for column in reversed(range(1, df.shape[1]+1)): # recording the name of specific clade in which we look for kmers\n",
    "            if len(df_temp.iloc[:,column-1].unique()) != 1 or (df_temp.iloc[:,column-1].unique()[0]) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                needed_column = column \n",
    "                break\n",
    "        specified_clade = []\n",
    "        \n",
    "        for col in range(2, needed_column):\n",
    "            specified_clade.append(df_temp.iloc[0, col])\n",
    "        specified_clade = map(str, specified_clade)           \n",
    "        specified_clade = '-'.join(specified_clade)\n",
    "        print(specified_clade)\n",
    "        clusters_in_clade = list(df_temp.iloc[:,1])\n",
    "        # print(clusters_in_clade)\n",
    "        \n",
    "        # clades to files \n",
    "        seqs_in_clades = []\n",
    "        if not os.path.exists('./clades/'):\n",
    "            os.mkdir('clades/')\n",
    "        f = open(f'./clades/{specified_clade}.fasta','w')\n",
    "        for cluster in clusters_in_clade:\n",
    "            seq_ids = seqs_in_clusters[cluster]\n",
    "            for seqid in seq_ids:\n",
    "                seqs_in_clades.append(f'>{seqid}|{specified_clade}')\n",
    "                seqs_in_clades.append(seqs_dict[seqid])\n",
    "        clade_size = len(seqs_in_clades)\n",
    "        for stroka in range(0, clade_size, 2):\n",
    "            seqs_in_clades[stroka] = seqs_in_clades[stroka] + f'|{clade_size}'       \n",
    "        f.writelines('\\n'.join(seqs_in_clades))\n",
    "        all_clades.writelines('\\n'.join(seqs_in_clades))\n",
    "        f.close()\n",
    "    all_clades.close()\n",
    "        \n",
    "        # generating dumps\n",
    "    if not os.path.exists('./dumps/'):\n",
    "        os.mkdir('./dumps/')\n",
    "    if not os.path.exists('./real_dumps/'):\n",
    "        os.mkdir('./real_dumps/')\n",
    "    os.chdir('./clades')\n",
    "    print(os.getcwd())\n",
    "    print('went?')\n",
    "    os.system(f'ls | xargs -P 3 -L 1 -I NAME jellyfish count -m {kmer_size} -s 100M -t 10 -C -o ../dumps/NAME.jf NAME')\n",
    "    print('went.')\n",
    "    os.chdir('..')\n",
    "    print(os.getcwd())\n",
    "    gd.gen_dumps()\n",
    "\n",
    "    # o = input()\n",
    "    os.chdir('../real_dumps/')\n",
    "    \n",
    "    arr = listdir_nohidden()\n",
    "    for dir in arr:\n",
    "        kmer_uniq(dir, kmer_size)\n",
    "    os.chdir('../')\n",
    "    os.system(f'jellyfish count -m {kmer_size} -s 100M -t 10 -C all_clades.fasta')\n",
    "    os.system('jellyfish dump mer_counts.jf > k_dump.fa')\n",
    "\n",
    "\n",
    "    f = open('k_dump.fa')\n",
    "    filtered_kmers = open('k_dump_filtered.fas', 'w')\n",
    "    filtered_list = []\n",
    "    k_list = []\n",
    "    kmer_names = []\n",
    "    lines = f.readlines()\n",
    "    n = 0\n",
    "\n",
    "    # max = 0\n",
    "    # for line in lines:\n",
    "    #     if '>' in line:\n",
    "    #         if int(line.strip()[1:]) > max:\n",
    "    #             max = int(line.strip()[1:])\n",
    "    # f.seek(0)\n",
    "    # lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if '>' in line:\n",
    "            if int(line.strip()[1:]) > min(maximums)//2 - 1:\n",
    "                filtered_list.append(line.strip())\n",
    "                switch = True\n",
    "            else:\n",
    "                switch = False\n",
    "        else:\n",
    "            if switch:\n",
    "                filtered_list.append(line.strip())\n",
    "    filtered_kmers.write('\\n'.join(filtered_list))\n",
    "    filtered_kmers.close()\n",
    "    f.close()\n",
    "\n",
    "    filtered_kmers = open('k_dump_filtered.fas')\n",
    "    # cluster = open('all_clades.fasta')\n",
    "    lines = filtered_kmers.readlines()\n",
    "    # clines = cluster.readlines()\n",
    "    m = 0\n",
    "    # kmer_names = []\n",
    "    for line in lines:\n",
    "        n=0\n",
    "        m+=1\n",
    "        # if m%5000 == 0:\n",
    "        #     print(m)\n",
    "        if '>' not in line:\n",
    "            kmer = line.strip()\n",
    "            kmer_names.append(line.strip())\n",
    "            rev_kmer = Seq(kmer)\n",
    "            rev_kmer = rev_kmer.reverse_complement()\n",
    "            n = os.system(f\"grep -e '{kmer}' -e '{rev_kmer}' ./all_clades.fasta | wc -l >> n.temp\")\n",
    "            # clines = cluster.readlines()\n",
    "            # for cline in clines:\n",
    "            #     rev_seq = Seq(cline.strip())\n",
    "            #     rev_seq = rev_seq.reverse_complement()\n",
    "            #     # if '>' not in cline:\n",
    "            #     if kmer in cline or kmer in rev_seq:\n",
    "            #         n+=1\n",
    "            if m%5000 == 0:\n",
    "                print(kmer, n)\n",
    "    k_list = [int(i.strip()) for i in open('n.temp').readlines()]\n",
    "    n = os.system('rm n.temp')\n",
    "    data = {'kmer':kmer_names, 'count':k_list}\n",
    "    uniq_doc_list = []\n",
    "    for c, v in enumerate(kmer_names):\n",
    "        count_value = f'>{k_list[c]}'\n",
    "        uniq_doc_list.append(count_value)\n",
    "        uniq_doc_list.append(v)\n",
    "    path_uniq = open('k_dump_uniq.fasta', 'w')\n",
    "    path_uniq.write('\\n'.join(uniq_doc_list))\n",
    "    path_uniq.close()\n",
    "    # os.system(f'rm ')\n",
    "    os.system(f'rm ./k_dump_filtered.fas')\n",
    "    # df = pd.DataFrame.from_dict(data)\n",
    "    filtered_kmers.close()\n",
    "    # cluster.close()\n",
    "    print('end')\n",
    "\n",
    "    \n",
    "    dtcsv()\n",
    "    os.system('rm -f ./clades/*')\n",
    "    os.system('rm -f ./dumps/*')\n",
    "    os.system('rm -f ./real_dumps/*')\n",
    "    os.system('rm -f k_dump.fa')\n",
    "    os.system('rm -f mer_counts.jf')\n",
    "    sys.exit()\n",
    "    \n",
    "def walk_tree(tree):\n",
    "    global leaves\n",
    "    leaves = []\n",
    "    leaf_list = {}\n",
    "    for k, v in tree.items():\n",
    "        get_leaves(v)\n",
    "        leaf_list[k] = leaves\n",
    "        leaves = []\n",
    "    # print(leaf_list)\n",
    "    # print('\\n')\n",
    "    \n",
    "    find_unique(leaf_list)\n",
    "    # find_unique_2()\n",
    "    '''\n",
    "    здесь добавить обработку найденных кмеров\n",
    "    '''\n",
    "    print('END OF PACK')\n",
    "    # cmd = 'rm -f ./clades/*'\n",
    "    # os.system(cmd)\n",
    "    \n",
    "    for k, v in tree.items():\n",
    "        if type(v) is dict:\n",
    "            walk_tree(v)\n",
    "kmer_size = int(input('Enter the size of k-mer'))        \n",
    "seqs_file = open('Alongiglumis_CN58138_pseudomolecules.v1.fasta.pass.list.REPEAT_REGIONS.gff3.fas')\n",
    "seqs_dict = {}\n",
    "for line in seqs_file.readlines():\n",
    "    if '>' in line:\n",
    "        k = line.strip().split(':')[1]\n",
    "    else:\n",
    "        seqs_dict[k] = line.strip()\n",
    "leaves = []\n",
    "walk_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2270ca55-f6be-4243-ace8-a19124d3015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for dir in arr:\n",
    "        kmer_uniq(dir, kmer_size)\n",
    "    os.chdir('../')\n",
    "    os.system(f'jellyfish count -m {kmer_size} -s 100M -t 10 -C all_clades.fasta')\n",
    "    os.system('jellyfish dump mer_counts.jf > k_dump.fa')\n",
    "    o = input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a4018-deff-42b5-ba71-36f87570c60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    f = open('k_dump.fa')\n",
    "    filtered_kmers = open('k_dump_filtered.fas', 'w')\n",
    "    filtered_list = []\n",
    "    k_list = []\n",
    "    kmer_names = []\n",
    "    lines = f.readlines()\n",
    "    n = 0\n",
    "\n",
    "    for line in lines:\n",
    "        if '>' in line:\n",
    "            if int(line.strip()[1:]) > 50:\n",
    "                filtered_list.append(line.strip())\n",
    "                switch = True\n",
    "            else:\n",
    "                switch = False\n",
    "        else:\n",
    "            if switch:\n",
    "                filtered_list.append(line.strip())\n",
    "    filtered_kmers.write('\\n'.join(filtered_list))\n",
    "    filtered_kmers.close()\n",
    "    f.close()\n",
    "\n",
    "    filtered_kmers = open('k_dump_filtered.fas')\n",
    "    cluster = open('all_clades.fasta')\n",
    "    lines = filtered_kmers.readlines()\n",
    "    # clines = cluster.readlines()\n",
    "    m = 0\n",
    "    for line in lines:\n",
    "        n=0\n",
    "        m+=1\n",
    "        if m%5000 == 0:\n",
    "            print(m)\n",
    "        if '>' not in line:\n",
    "            kmer = line.strip()\n",
    "            kmer_names.append(line.strip())\n",
    "            clines = cluster.readlines()\n",
    "            for cline in clines:\n",
    "                rev_seq = Seq(cline.strip())\n",
    "                rev_seq = rev_seq.reverse_complement()\n",
    "                # if '>' not in cline:\n",
    "                if kmer in cline or kmer in rev_seq:\n",
    "                    n+=1\n",
    "            if m%5000 == 0:\n",
    "                print(kmer, n)\n",
    "            k_list.append(n)\n",
    "            cluster.seek(0)\n",
    "    data = {'kmer':kmer_names, 'count':k_list}\n",
    "    uniq_doc_list = []\n",
    "    for c, v in enumerate(kmer_names):\n",
    "        count_value = f'>{k_list[c]}'\n",
    "        uniq_doc_list.append(count_value, v)\n",
    "    path_uniq = open('k_dump_uniq.fasta', 'w')\n",
    "    path_uniq.write('\\n'.join(uniq_doc_list))\n",
    "    path_uniq.close()\n",
    "    os.system('rm k_dump_filtered.fas')\n",
    "    # df = pd.DataFrame.from_dict(data)\n",
    "    filtered_kmers.close()\n",
    "    cluster.close()\n",
    "    print('end')\n",
    "\n",
    "    \n",
    "    dtcsv()\n",
    "    os.system('rm -f ./clades/*')\n",
    "    os.system('rm -f ./dumps/*')\n",
    "    os.system('rm -f ./real_dumps/*')\n",
    "    os.system('rm -f k_dump.fa')\n",
    "    os.system('rm -f mer_counts.jf')\n",
    "    sys.exit()\n",
    "    \n",
    "def walk_tree(tree):\n",
    "    global leaves\n",
    "    leaves = []\n",
    "    leaf_list = {}\n",
    "    for k, v in tree.items():\n",
    "        get_leaves(v)\n",
    "        leaf_list[k] = leaves\n",
    "        leaves = []\n",
    "    # print(leaf_list)\n",
    "    # print('\\n')\n",
    "    \n",
    "    find_unique(leaf_list)\n",
    "    # find_unique_2()\n",
    "    '''\n",
    "    здесь добавить обработку найденных кмеров\n",
    "    '''\n",
    "    print('END OF PACK')\n",
    "    # cmd = 'rm -f ./clades/*'\n",
    "    # os.system(cmd)\n",
    "    \n",
    "    for k, v in tree.items():\n",
    "        if type(v) is dict:\n",
    "            walk_tree(v)\n",
    "kmer_size = int(input('Enter the size of k-mer'))        \n",
    "seqs_file = open('Alongiglumis_CN58138_pseudomolecules.v1.fasta.pass.list.REPEAT_REGIONS.gff3.fas')\n",
    "seqs_dict = {}\n",
    "for line in seqs_file.readlines():\n",
    "    if '>' in line:\n",
    "        k = line.strip().split(':')[1]\n",
    "    else:\n",
    "        seqs_dict[k] = line.strip()\n",
    "leaves = []\n",
    "walk_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1cbe02-b016-4710-96b7-9f80defe43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_groups_OLD(df, column):\n",
    "#     grps = {}\n",
    "#     n = 0\n",
    "#     for i in df.iloc[:,column]:\n",
    "#         n+=1\n",
    "#         if i not in grps:\n",
    "#             grps[i] = []        \n",
    "#         grps[i].append(n-1)\n",
    "#     return(grps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d386855-730d-433a-ab25-aff10ee59f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 9, 2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8174d921-e3fe-4e28-a95d-6bfe56758103",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0 == 0.0:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852e1aa9-378b-4ed9-b797-2c6a03e0758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = []\n",
    "lol.append(3)\n",
    "lol.append([3,4])\n",
    "lol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
